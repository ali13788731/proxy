import requests
import re
import json
import html
import socket
import time
import jdatetime  # Ø¨Ø±Ø§ÛŒ ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ
from concurrent.futures import ThreadPoolExecutor

# Ù„ÛŒØ³Øª Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ©Ø³ÛŒ
CHANNELS = [
    "Myporoxy", "TelMTProto", "ProxyMTProto", "mt_p_roxy", 
    "ProxyHagh", "MTProtoProxies", "PinkProxy", "v2rayng_vpn"
]

def get_ping(server, port):
    """ØªØ³Øª Ù¾ÛŒÙ†Ú¯ ÙˆØ§Ù‚Ø¹ÛŒ (Ø§ØªØµØ§Ù„ TCP)"""
    try:
        start = time.time()
        # Ú©Ø§Ù‡Ø´ ØªØ§ÛŒÙ…â€ŒØ§ÙˆØª Ø¨Ù‡ 1.5 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
        sock = socket.create_connection((server, int(port)), timeout=1.5)
        sock.close()
        return int((time.time() - start) * 1000)
    except:
        return 9999

def process_proxy(link):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ ØªØ³Øª Ù¾ÛŒÙ†Ú¯ Ù‡Ø± Ù„ÛŒÙ†Ú©"""
    try:
        # ØªØ¨Ø¯ÛŒÙ„ Ù„ÛŒÙ†Ú© ÙˆØ¨ Ø¨Ù‡ Ù„ÛŒÙ†Ú© Ù…Ø³ØªÙ‚ÛŒÙ… ØªÙ„Ú¯Ø±Ø§Ù…
        if "https://t.me/proxy" in link:
            link = link.replace("https://t.me/proxy", "tg://proxy")
            
        server = re.search(r'server=([\w\.\-\[\]:]+)', link).group(1)
        port = re.search(r'port=(\d+)', link).group(1)
        secret = re.search(r'secret=([\w\.\-\%]+)', link).group(1)
        
        ping = get_ping(server, port)
        
        # ÙÙ‚Ø· Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ù¾ÛŒÙ†Ú¯ Ø²ÛŒØ± 3000 Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡
        if ping < 3000: 
            return {
                "server": server,
                "port": port,
                "secret": secret,
                "link": link,
                "ping": ping
            }
    except:
        return None

def main():
    print("ğŸš€ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§...")
    raw_links = []
    for chan in CHANNELS:
        try:
            url = f"https://t.me/s/{chan}"
            res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)
            clean_text = html.unescape(res.text)
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§
            links = re.findall(r'(?:https://t\.me/|tg://)proxy\?(?:[^"\s>]+)', clean_text)
            raw_links.extend(links)
            print(f"âœ… {chan}: {len(links)} ÛŒØ§ÙØª Ø´Ø¯.")
        except:
            continue

    unique_links = list(set(raw_links))
    valid_proxies = []

    # Ù¾ÛŒÙ†Ú¯ Ù…ÙˆØ§Ø²ÛŒ
    print(f"âš¡ Ø¯Ø± Ø­Ø§Ù„ ØªØ³Øª Ù¾ÛŒÙ†Ú¯ {len(unique_links)} Ù¾Ø±ÙˆÚ©Ø³ÛŒ...")
    with ThreadPoolExecutor(max_workers=50) as executor:
        results = executor.map(process_proxy, unique_links)
        for r in results:
            if r: valid_proxies.append(r)

    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ: Ú©Ù…ØªØ±ÛŒÙ† Ù¾ÛŒÙ†Ú¯ Ø§ÙˆÙ„ Ù„ÛŒØ³Øª
    valid_proxies.sort(key=lambda x: x['ping'])

    # Ø¯Ø±ÛŒØ§ÙØª Ø²Ù…Ø§Ù† ÙØ¹Ù„ÛŒ Ø¨Ù‡ ÙˆÙ‚Øª Ø§ÛŒØ±Ø§Ù† (Ø´Ù…Ø³ÛŒ)
    # Ø¨Ø§ ÙØ±Ø¶ Ø§ÛŒÙ†Ú©Ù‡ Ø³Ø±ÙˆØ± Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨ UTC Ø§Ø³ØªØŒ Û³:Û³Û° Ø³Ø§Ø¹Øª Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ÛŒØ§ Ø§Ø² Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ§ÛŒÙ…â€ŒØ²ÙˆÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    # Ø§ÛŒÙ†Ø¬Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø²Ù…Ø§Ù† Ø±Ø§ ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    now_shamsi = jdatetime.datetime.now().strftime("%Y/%m/%d - %H:%M")

    # Ø³Ø§Ø®ØªØ§Ø± Ù†Ù‡Ø§ÛŒÛŒ Ø¬ÛŒØ³ÙˆÙ†
    final_output = {
        "last_updated": now_shamsi,
        "proxies": valid_proxies
    }

    with open("proxies.json", "w", encoding="utf-8") as f:
        json.dump(final_output, f, indent=4, ensure_ascii=False)
    
    print(f"ğŸ ØªÙ…Ø§Ù… Ø´Ø¯. {len(valid_proxies)} Ù¾Ø±ÙˆÚ©Ø³ÛŒ ÙØ¹Ø§Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯. Ø²Ù…Ø§Ù†: {now_shamsi}")

if __name__ == "__main__":
    main()
