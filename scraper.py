import requests

import re

import json

import html

import socket

import time

import jdatetime  # Ø¨Ø±Ø§ÛŒ ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ

from datetime import datetime, timedelta # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ØµÙ„Ø§Ø­ Ø³Ø§Ø¹Øª

from concurrent.futures import ThreadPoolExecutor



# Ù„ÛŒØ³Øª Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ©Ø³ÛŒ

CHANNELS = [

    "Myporoxy", "TelMTProto", "ProxyMTProto", "mt_p_roxy", 

    "ProxyHagh", "MTProtoProxies", "PinkProxy", "v2rayng_vpn"

]



def get_ping(server, port):

    """ØªØ³Øª Ù¾ÛŒÙ†Ú¯ ÙˆØ§Ù‚Ø¹ÛŒ (Ø§ØªØµØ§Ù„ TCP)"""

    try:

        start = time.time()

        # Ú©Ø§Ù‡Ø´ ØªØ§ÛŒÙ…â€ŒØ§ÙˆØª Ø¨Ù‡ 1.5 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±

        sock = socket.create_connection((server, int(port)), timeout=1.5)

        sock.close()

        return int((time.time() - start) * 1000)

    except:

        return 9999



def process_proxy(link):

    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ ØªØ³Øª Ù¾ÛŒÙ†Ú¯ Ù‡Ø± Ù„ÛŒÙ†Ú©"""

    try:

        # ØªØ¨Ø¯ÛŒÙ„ Ù„ÛŒÙ†Ú© ÙˆØ¨ Ø¨Ù‡ Ù„ÛŒÙ†Ú© Ù…Ø³ØªÙ‚ÛŒÙ… ØªÙ„Ú¯Ø±Ø§Ù…

        if "https://t.me/proxy" in link:

            link = link.replace("https://t.me/proxy", "tg://proxy")

            

        server = re.search(r'server=([\w\.\-\[\]:]+)', link).group(1)

        port = re.search(r'port=(\d+)', link).group(1)

        secret = re.search(r'secret=([\w\.\-\%]+)', link).group(1)

        

        ping = get_ping(server, port)

        

        # ÙÙ‚Ø· Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ù¾ÛŒÙ†Ú¯ Ø²ÛŒØ± 3000 Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡

        if ping < 3000: 

            return {

                "server": server,

                "port": port,

                "secret": secret,

                "link": link,

                "ping": ping

            }

    except:

        return None



def main():

    print("ğŸš€ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§...")

    raw_links = []

    for chan in CHANNELS:

        try:

            url = f"https://t.me/s/{chan}"

            res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)

            clean_text = html.unescape(res.text)

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§

            links = re.findall(r'(?:https://t\.me/|tg://)proxy\?(?:[^"\s>]+)', clean_text)

            raw_links.extend(links)

            print(f"âœ… {chan}: {len(links)} ÛŒØ§ÙØª Ø´Ø¯.")

        except:

            continue



    unique_links = list(set(raw_links))

    valid_proxies = []



    # Ù¾ÛŒÙ†Ú¯ Ù…ÙˆØ§Ø²ÛŒ

    print(f"âš¡ Ø¯Ø± Ø­Ø§Ù„ ØªØ³Øª Ù¾ÛŒÙ†Ú¯ {len(unique_links)} Ù¾Ø±ÙˆÚ©Ø³ÛŒ...")

    with ThreadPoolExecutor(max_workers=50) as executor:

        results = executor.map(process_proxy, unique_links)

        for r in results:

            if r: valid_proxies.append(r)



    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ: Ú©Ù…ØªØ±ÛŒÙ† Ù¾ÛŒÙ†Ú¯ Ø§ÙˆÙ„ Ù„ÛŒØ³Øª

    valid_proxies.sort(key=lambda x: x['ping'])



    # --- Ø§ØµÙ„Ø§Ø­ Ø¨Ø®Ø´ Ø²Ù…Ø§Ù† (Fix Timezone) ---

    # Ø¯Ø±ÛŒØ§ÙØª Ø²Ù…Ø§Ù† Ø¬Ù‡Ø§Ù†ÛŒ (UTC) Ø§Ø² Ø³Ø±ÙˆØ±

    utc_now = datetime.utcnow()

    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Û³:Û³Û° Ø³Ø§Ø¹Øª Ø¨Ø±Ø§ÛŒ Ø±Ø³ÛŒØ¯Ù† Ø¨Ù‡ ÙˆÙ‚Øª Ø§ÛŒØ±Ø§Ù†

    tehran_time = utc_now + timedelta(hours=3, minutes=30)

    # ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ ØªÙ‡Ø±Ø§Ù† Ø¨Ù‡ Ø´Ù…Ø³ÛŒ

    now_shamsi = jdatetime.datetime.fromgregorian(datetime=tehran_time).strftime("%Y/%m/%d - %H:%M")

    # -------------------------------------



    # Ø³Ø§Ø®ØªØ§Ø± Ù†Ù‡Ø§ÛŒÛŒ Ø¬ÛŒØ³ÙˆÙ†

    final_output = {

        "last_updated": now_shamsi,

        "proxies": valid_proxies

    }



    with open("proxies.json", "w", encoding="utf-8") as f:

        json.dump(final_output, f, indent=4, ensure_ascii=False)

    

    print(f"ğŸ ØªÙ…Ø§Ù… Ø´Ø¯. {len(valid_proxies)} Ù¾Ø±ÙˆÚ©Ø³ÛŒ ÙØ¹Ø§Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯. Ø²Ù…Ø§Ù†: {now_shamsi}")



if __name__ == "__main__":

    main()
